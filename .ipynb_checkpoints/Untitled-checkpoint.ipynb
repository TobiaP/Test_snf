{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "215e1f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import axis\n",
    "from numpy import linalg as la\n",
    "\n",
    "def normalize(x):\n",
    "    for it, row in enumerate(x):\n",
    "        x[it] = row / np.sqrt(np.sum(row**2))\n",
    "    return x\n",
    "\n",
    "def discetizationEigenVectorData(eigenVector):\n",
    "    Y = np.array([[0.0 for _ in range(len(eigenVector[0]))] for _ in range(len(eigenVector))])\n",
    "    j = []\n",
    "    for row in eigenVector:\n",
    "        j.append(np.unravel_index(row.argmax(), row.shape))\n",
    "    for it, i in enumerate(j):\n",
    "        Y[it][i[0]] = 1\n",
    "    return Y \n",
    "\n",
    "def discretization(eigenVectors):\n",
    "    eigenVectors = normalize(eigenVectors)\n",
    "    n = len(eigenVectors)\n",
    "    k = len(eigenVectors[0])\n",
    "    \n",
    "    R = np.array([[0.0 for _ in range(k)] for _ in range(k)])\n",
    "    R[:,0] = np.transpose(eigenVectors[round(n/2)-1])\n",
    "    \n",
    "    c = np.array([0 for _ in range(n)])\n",
    "    c = np.reshape(c, (n,1))\n",
    "    for j in range(1,k):\n",
    "        c = c + abs(np.matmul(eigenVectors, np.reshape(R[:,j-1], (k,1))))    \n",
    "        i = np.unravel_index(c.argmin(), c.shape)\n",
    "        R[:,j] = np.transpose(eigenVectors[i[0]])\n",
    "    lastObjectiveValue = 0\n",
    "    for i in range(20):\n",
    "        eigenDiscrete = discetizationEigenVectorData(np.matmul(eigenVectors, R))\n",
    "        u,s,v = la.svd(np.matmul(np.transpose(eigenDiscrete), eigenVectors))\n",
    "        v=np.transpose(v)\n",
    "        NcutValue = 2*(n-np.sum(s))\n",
    "        if abs(NcutValue-lastObjectiveValue) < np.finfo(float).eps:\n",
    "            break\n",
    "        \n",
    "        lastObjectiveValue = NcutValue\n",
    "        R = np.matmul(v, np.transpose(u))\n",
    "    return eigenDiscrete\n",
    "    \n",
    "def SpectralClustering(affinity, K, type=3):\n",
    "    \n",
    "    d = np.sum(affinity, axis=1)\n",
    "    for it, i in enumerate(d):\n",
    "        if i == 0:\n",
    "            d[it] = np.finfo(float).eps\n",
    "            \n",
    "    D = np.diag(d)\n",
    "    L = D - affinity\n",
    "    if type == 1:\n",
    "        NL = L\n",
    "    elif type == 2:\n",
    "        Di = np.diag(1/d)\n",
    "        NL = Di * L\n",
    "    elif type == 3:\n",
    "        Di = np.diag(1/np.sqrt(d))\n",
    "        NL = np.matmul(Di,L)\n",
    "        NL = np.matmul(NL,Di)\n",
    "    \n",
    "    eig = la.eig(NL)\n",
    "    res = sorted(range(len(eig[0])), key=lambda k: eig[0][k])\n",
    "    U = eig[1][:,res[0:K]]\n",
    "    if type == 3:\n",
    "        U = normalize(U)\n",
    "    eigDiscrete = discretization(U)\n",
    "    labels = []\n",
    "    for row in eigDiscrete:\n",
    "        labels.append(np.unravel_index(row.argmax(), row.shape)[0])\n",
    "    for it, i in enumerate(labels):\n",
    "        labels[it] = i + 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5750ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snf\n",
    "from snf import get_n_clusters\n",
    "from data_convert import load_data_txt\n",
    "from random import seed\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "def generateCVRuns(data, N=10, K=5):\n",
    "    mats = []\n",
    "    seed(N)\n",
    "    for i in range(N):\n",
    "        seq = np.arange(len(data))\n",
    "        shuffle(seq)\n",
    "        mat = np.array_split(seq, K)\n",
    "        mats.append(mat)\n",
    "    return mats\n",
    "\n",
    "datas = load_data_txt(r\"C:\\Users\\tpavo\\Desktop\\Tirocinio\\tcga_aml\\OS\\0\\gene_tr_0_0.txt\", r\"C:\\Users\\tpavo\\Desktop\\Tirocinio\\tcga_aml\\OS\\0\\meth_tr_0_0.txt\", r\"C:\\Users\\tpavo\\Desktop\\Tirocinio\\tcga_aml\\OS\\0\\mirna_tr_0_0.txt\", r\"C:\\Users\\tpavo\\Desktop\\Tirocinio\\tcga_aml\\OS\\0\\labels_OS_tr_0_0.txt\")\n",
    "affinity_networks = snf.make_affinity(datas.data, K=20, mu=0.5)\n",
    "W = snf.snf(affinity_networks, K=20)\n",
    "lab = datas.labels\n",
    "clm = 'spectral'\n",
    "clustInfo = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0bf892b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snf_cv(W, lab, clm, infocl, K=5, N=10):\n",
    "    median_NMI = []\n",
    "    nsamp = len(W)\n",
    "    SNFNMI_all = []\n",
    "    cv_folds = generateCVRuns(lab)\n",
    "    for nfold in cv_folds:\n",
    "        SNFNMI_K = []\n",
    "        for row in nfold:\n",
    "            W_k = W[np.ix_(row, row)]\n",
    "            lab_k = []\n",
    "            for el in row:\n",
    "                lab_k.append(lab[el])\n",
    "            if clm == 'spectral':\n",
    "                if clustInfo:\n",
    "                    nclust = len(np.unique(lab))\n",
    "                    group_k = SpectralClustering(W_k, nclust)\n",
    "                else:\n",
    "                    nclust = get_n_clusters(W_k)\n",
    "                    group_k = SpectralClustering(W_k, nclust[0])\n",
    "            SNFNMI_K.append(normalized_mutual_info_score(group_k, lab_k))\n",
    "        median_NMI.append(np.median(SNFNMI_K))\n",
    "    median_NMI = np.median(median_NMI)\n",
    "    return median_NMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2a699a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08343009733226453"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snf_cv(W, lab, 'spectral', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0bd771b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snf\n",
    "from snf import get_n_clusters\n",
    "from data_convert import load_data_txt\n",
    "from random import seed\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "def generateCVRuns(data, N=10, K=5):\n",
    "    mats = []\n",
    "    seed(N)\n",
    "    for i in range(N):\n",
    "        seq = np.arange(len(data))\n",
    "        shuffle(seq)\n",
    "        mat = np.array_split(seq, K)\n",
    "        mats.append(mat)\n",
    "    return mats\n",
    "\n",
    "def snf_cv(W, lab, clm, infocl, K=5, N=10):\n",
    "    median_NMI = []\n",
    "    nsamp = len(W)\n",
    "    SNFNMI_all = []\n",
    "    cv_folds = generateCVRuns(lab)\n",
    "    for nfold in cv_folds:\n",
    "        SNFNMI_K = []\n",
    "        for row in nfold:\n",
    "            W_k = W[np.ix_(row, row)]\n",
    "            lab_k = []\n",
    "            for el in row:\n",
    "                lab_k.append(lab[el])\n",
    "            if clm == 'spectral':\n",
    "                if clustInfo:\n",
    "                    nclust = len(np.unique(lab))\n",
    "                    group_k = SpectralClustering(W_k, nclust)\n",
    "                else:\n",
    "                    nclust = get_n_clusters(W_k)\n",
    "                    group_k = SpectralClustering(W_k, nclust[0])\n",
    "            SNFNMI_K.append(normalized_mutual_info_score(group_k, lab_k))\n",
    "        median_NMI.append(np.median(SNFNMI_K))\n",
    "    median_NMI = np.median(median_NMI)\n",
    "    return median_NMI\n",
    "            \n",
    "\n",
    "def NMI_tuning(distL, K, alpha, lab, clm, infocl):\n",
    "    affinityL = snf.make_affinity(distL, K=K, mu=alpha)\n",
    "    W_K = snf.snf(affinityL, K=K)\n",
    "    return snf_cv(W_K, lab, clm=clm, infocl=infocl)\n",
    "\n",
    "def snf_tuning(distL, lab, clm, infocl):\n",
    "    #min and max K values\n",
    "    minK = 10\n",
    "    maxK = 30\n",
    "    stepK = 1\n",
    "    K_values = range(minK, maxK+stepK, stepK)\n",
    "    \n",
    "    #min and max alpha values\n",
    "    min_alpha = 0.3\n",
    "    max_alpha = 0.8\n",
    "    step_alpha = 0.05\n",
    "    alpha_values = np.arange(min_alpha, max_alpha+step_alpha, step_alpha)\n",
    "    \n",
    "    NMI_tun = Parallel(n_jobs=2)(delayed(NMI_tuning)(distL, k, alpha, lab, clm, infocl) for k in K_values for alpha in alpha_values)\n",
    "    \n",
    "    nk = len(K_values)\n",
    "    nalpha = len(alpha_values)\n",
    "    \n",
    "    idx_max_alpha_fk = []\n",
    "    max_nmi_fk = []\n",
    "    tab_median_NMI = []\n",
    "    \n",
    "    for elk in range(nK):\n",
    "        max_nmi_fk.append(max(NMI_tun[elk]))\n",
    "        tab_median_NMI.append(NMI_tun[elk])\n",
    "        \n",
    "    best_K_idx = np.unravel_index(max_nmi_fk.argmax(), max_nmi_fk.shape)\n",
    "    best_K = K_values[best_K_idx]\n",
    "    \n",
    "    best_alpha_idx = np.unravel_index(NMI_tun.argmax(), NMI_tun.shape)\n",
    "    best_alpha = alpha_values[best_alpha_idx]\n",
    "\n",
    "    return Bunch(best_K=best_K, best_alpha=best_alpha, tab_median_NMI=tab_median_NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3622e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
