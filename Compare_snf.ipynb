{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc346168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Tuning\n",
      "\n",
      "38.670s elapsed\n",
      "End Tuning K = 16 alpha = 0.39999999999999997\n",
      "\n",
      "### Similarity graphs creation\n",
      "### Graph fusion\n",
      "0.032s elapsed\n",
      "### Estimating number of clusters\n",
      "### Spectral clustering\n",
      "0.014s elapsed\n",
      "\n",
      "0.069s elapsed overall\n",
      "\n",
      "Est. number of clusters = 4\n",
      "NMI = 0.06739\n",
      "R parameters: ['10\\n', '0.35\\n']\n",
      "Python parameters: K: 16 alpha : 0.39999999999999997\n",
      "\n",
      "Differences between affinity matrices:\n",
      "\n",
      "Mean difference: 0.001810225967623623\n",
      "average percentage difference: 226374.60486785683\n",
      "\n",
      "Mean difference: 0.0019691165701495763\n",
      "average percentage difference: 1432570.6804486113\n",
      "\n",
      "Mean difference: 0.0017429136029823622\n",
      "average percentage difference: 106060.3427735406\n",
      "\n",
      "Differences between snf:\n",
      "\n",
      "Mean difference: 0.011778750237204151\n",
      "average percentage difference: 188.27347835436706\n",
      "\n",
      "Differences between scaled snf:\n",
      "\n",
      "Mean difference: 0.015690832343138967\n",
      "average percentage difference: 329.44436001282804\n",
      "\n",
      "Cluster Differences\n",
      "0.32907562770848364\n",
      "\n",
      "SNFNMI_allfeats:\n",
      "\n",
      "0.0489381348175063 0.06738709426218203 -0.018448959444675735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tpavo\\anaconda3\\envs\\Test\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:658: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# This takes the results of SNF.py and snf_integration.r and compares them\n",
    "import snf\n",
    "from snf import get_n_clusters\n",
    "from calNMI import calNMI\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import v_measure_score, normalized_mutual_info_score\n",
    "from data_convert import load_data_txt, load_mat\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "from snf_tuning import snf_tuning\n",
    "from timeit import default_timer as timer\n",
    "# class myArgumentParser(argparse.ArgumentParser):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super(myArgumentParser, self).__init__(*args, **kwargs)\n",
    "\n",
    "#     def convert_arg_line_to_args(self, line):\n",
    "#         for arg in line.split():\n",
    "#             if not arg.strip():\n",
    "#                 continue\n",
    "#             if arg[0] == '#':\n",
    "#                 break\n",
    "#             yield arg\n",
    "            \n",
    "# parser = myArgumentParser(\n",
    "#     description='compares results from SNF.py and snf_integration.r .',\n",
    "#     fromfile_prefix_chars='@',\n",
    "# )\n",
    "# parser.add_argument('--DATAFILE', type=str, help='Training datafile')\n",
    "# parser.add_argument('--OUTDIR', type=str, help='Output directory')\n",
    "# parser.add_argument('--DATASET', type=str, help='dataset')\n",
    "# parser.add_argument('--TARGET', type=str, help='target')\n",
    "# parser.add_argument('--SPLIT_ID', type=str, help='split_id')\n",
    "# parser.add_argument('--LAYERS', type=str, help='layers')\n",
    "# parser.add_argument('--MODEL', type=str, help='model')\n",
    "# parser.add_argument('--OUTFILE', type=str, help='outfile')\n",
    "# parser.add_argument('--LAB', type=str, help=\"lab file\")\n",
    "# parser.add_argument('--CLUST', type=str, help=\"Clusteringmethod on fused graph\")\n",
    "# parser.add_argument('--CLUSTINFO', type=str, help=\"Should the number of clusters be equal to the number of classes?\")\n",
    "# parser.add_argument('--THREADS', type=str, help=\"Number of threads for rSNF\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# CV_K = args.OUTFILE[-5]\n",
    "# CV_N = args.OUTFILE[-7]\n",
    "# LAYERS = args.LAYERS.split(\"_\")\n",
    "# DATASET = args.DATASET\n",
    "# TARGET = args.TARGET\n",
    "# SPLIT_ID = args.SPLIT_ID\n",
    "# MODEL = args.MODEL\n",
    "# IN_DIR = args.DATAFILE + \"/\" + DATASET + \"/\" + TARGET + \"/\" + SPLIT_ID + \"/\"\n",
    "# OUT_DIR = args.OUTDIR + \"/\" + DATASET + \"/\" + TARGET + \"/\" + MODEL + \"/\" + SPLIT_ID + \"/rSNF/\"\n",
    "# LAB = args.LAB\n",
    "# clustMethod = args.CLUST\n",
    "# clustInfo = args.CLUSTINFO\n",
    "# threads = args.THREADS\n",
    "\n",
    "CV_N = 4\n",
    "CV_K = 3\n",
    "LAYERS = ['gene','mirna','meth']\n",
    "IN_DIR = r\"C:/Users/tpavo/Desktop/Tirocinio/tcga_aml/OS/1/\"\n",
    "OUT_DIR = r\"C:/Users/tpavo/Desktop/Prova/results/\"\n",
    "LAB = IN_DIR  + \"labels_OS\" + \"_tr_\" + str(CV_N) + \"_\" + str(CV_K) + \".txt\"\n",
    "clustMethod = 'spectral'\n",
    "clustInfo = False\n",
    "\n",
    "def difference(mat1, mat2):\n",
    "    avg_diff = 0\n",
    "    avg_per = 0\n",
    "    for row in range(len(mat1)):\n",
    "        div = abs(mat2[row]-mat1[row])\n",
    "        avg_diff += np.mean(div)\n",
    "        per = (100 * div)/mat1[row]\n",
    "        avg_per += np.mean(per)\n",
    "    avg_diff /= len(mat1)\n",
    "    avg_per /= len(mat1)\n",
    "    outstr = \"Mean difference: \" + str(avg_diff) + \"\\naverage percentage difference: \" + str(avg_per) + \"\\n\"\n",
    "    print(outstr)\n",
    "    return outstr\n",
    "\n",
    "files = []\n",
    "for l in range(3): \n",
    "    files.append(IN_DIR  + LAYERS[l] + \"_tr_\" + str(CV_N) + \"_\" + str(CV_K) + \".txt\")\n",
    "datas = load_data_txt(files[0], files[1], files[2], LAB)\n",
    "\n",
    "\n",
    "\n",
    "# tuning\n",
    "print(\"Start Tuning\\n\")\n",
    "start0 = timer()\n",
    "opt_par = snf_tuning(datas)\n",
    "end = timer()\n",
    "print(f\"{end - start0:.3f}s elapsed\")\n",
    "K = opt_par.K_opt\n",
    "mu = opt_par.mu_opt\n",
    "print(\"End Tuning K = \" + str(K) + \" alpha = \" + str(mu) + \"\\n\")\n",
    "\n",
    "# create similarity (affinity) networks\n",
    "print(\"### Similarity graphs creation\")\n",
    "start0 = timer()\n",
    "affinity_networks = snf.make_affinity(datas.data, metric='euclidean', K=K, mu=mu)\n",
    "end = timer()\n",
    "\n",
    "# network fusion\n",
    "print(\"### Graph fusion\")\n",
    "start = timer()\n",
    "fused_network = snf.snf(affinity_networks, K=K)\n",
    "end = timer()\n",
    "print(f\"{end - start:.3f}s elapsed\")\n",
    "\n",
    "# rescaled matrix\n",
    "fused_network_sc = fused_network / np.max(fused_network)\n",
    "\n",
    "# clustering \n",
    "if clustMethod == 'spectral':\n",
    "    if clustInfo:\n",
    "        nclust = len(np.unique(datas.labels))\n",
    "        lab = SpectralClustering(n_clusters=nclust, affinity='precomputed', assign_labels='discretize', random_state=11).fit_predict(fused_network)\n",
    "    else:\n",
    "        print(\"### Estimating number of clusters\")\n",
    "        start = timer()\n",
    "        best, _ = get_n_clusters(fused_network)\n",
    "        print(\"### Spectral clustering\")p\n",
    "        fused_labels = SpectralClustering(n_clusters=best, affinity='precomputed', eigen_solver = 'amg', assign_labels='discretize', random_state=11).fit_predict(fused_network)\n",
    "        end0 = timer()\n",
    "        print(f\"{end0 - start:.3f}s elapsed\")\n",
    "        nmi = v_measure_score(datas.labels, fused_labels)  \n",
    "        print()\n",
    "        print(f\"{end0 - start0:.3f}s elapsed overall\")\n",
    "        print()\n",
    "        print(f\"Est. number of clusters = {best}\")\n",
    "        print(f\"NMI = {nmi:.5f}\")\n",
    "\n",
    "# read R files\n",
    "p = open(OUT_DIR + \"INF\" + \"_tr_\" + str(CV_N) + \"_\" + str(CV_K) + \"_NMI_score.txt\")\n",
    "labsR = p.readlines()\n",
    "p.close()\n",
    "Rlabs = []\n",
    "for it, label in enumerate(fused_labels):\n",
    "    Rlabs.append(int(labsR[it+1]))\n",
    "\n",
    "# output        \n",
    "paths = []\n",
    "for f in range(3):\n",
    "    paths.append(OUT_DIR + \"INF\" + \"_tr_\" + str(CV_N) + \"_\" + str(CV_K) + \"_\" + str(f) + \"_mat.txt\")\n",
    "paths.append(OUT_DIR + \"INF\" + \"_tr_\" + str(CV_N) + \"_\" + str(CV_K) + \".txt\")\n",
    "paths.append(OUT_DIR + \"INF\" + \"_tr_\" + str(CV_N) + \"_\" + str(CV_K) + \"_similarity_mat_fused.txt\")\n",
    "        \n",
    "mats = load_mat(paths)\n",
    "        \n",
    "p = open(OUT_DIR + \"INF\" + \"_tr_\" + str(CV_N) + \"_\" + str(CV_K) + \"_NMI_score.txt\")\n",
    "mats.append(float(p.readline()))\n",
    "p.close()        \n",
    "        \n",
    "p = open(OUT_DIR + \"INF\" + \"_tr_\" + str(CV_N) + \"_\" + str(CV_K) + \"_OPT.txt\")\n",
    "mats.append(p.readlines())\n",
    "p.close()        \n",
    "        \n",
    "outf = open(OUT_DIR + \"Diff\" + str(CV_N) + \"_\" + str(CV_K) + \".txt\", \"w\")\n",
    "outf.write(\"opt_parameters difference\\n\")\n",
    "print(\"R parameters: \" + str(mats[6]) + \"\\n\" + \"Python parameters: K: \" + str(K) + \" alpha : \" + str(mu) + \"\\n\")\n",
    "outf.write(\"Differences between affinity matrices:\\n\")\n",
    "print(\"Differences between affinity matrices:\\n\")\n",
    "outf.write(difference(mats[0], affinity_networks[0]))\n",
    "outf.write(difference(mats[1], affinity_networks[1]))\n",
    "outf.write(difference(mats[2], affinity_networks[2]))\n",
    "outf.write(\"Differences between snf:\\n\")\n",
    "print(\"Differences between snf:\\n\")\n",
    "outf.write(difference(mats[3], fused_network))\n",
    "outf.write(\"Differences between scaled snf:\\n\")\n",
    "print(\"Differences between scaled snf:\\n\")\n",
    "outf.write(difference(mats[4], fused_network_sc))\n",
    "print(\"Cluster Differences\\n\" + str(v_measure_score(fused_labels, Rlabs)) + \"\\n\")\n",
    "outf.write(\"Cluster Differences\\n\" + str(v_measure_score(fused_labels, Rlabs)) + \"\\n\")\n",
    "print(\"SNFNMI_allfeats:\\n\")\n",
    "outf.write(\"SNFNMI_allfeats:\\n\" + str(mats[5] - nmi))\n",
    "print(str(mats[5]) + \" \" + str(nmi) + \" \" + str(mats[5] - nmi))\n",
    "     \n",
    "outf.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01d724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eeea12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
