{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b1577cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import axis\n",
    "from numpy import linalg as la\n",
    "\n",
    "def normalize(x):\n",
    "    for it, row in enumerate(x):\n",
    "        x[it] = row / np.sqrt(np.sum(row**2))\n",
    "    return x\n",
    "\n",
    "def discetizationEigenVectorData(eigenVector):\n",
    "    Y = np.array([[0.0 for _ in range(len(eigenVector[0]))] for _ in range(len(eigenVector))])\n",
    "    j = []\n",
    "    for row in eigenVector:\n",
    "        j.append(np.unravel_index(row.argmax(), row.shape))\n",
    "    for it, i in enumerate(j):\n",
    "        Y[it][i[0]] = 1\n",
    "    return Y \n",
    "\n",
    "def discretization(eigenVectors):\n",
    "    eigenVectors = normalize(eigenVectors)\n",
    "    n = len(eigenVectors)\n",
    "    k = len(eigenVectors[0])\n",
    "    \n",
    "    R = np.array([[0.0 for _ in range(k)] for _ in range(k)])\n",
    "    R[:,0] = np.transpose(eigenVectors[round(n/2)-1])\n",
    "    \n",
    "    c = np.array([0 for _ in range(n)])\n",
    "    c = np.reshape(c, (n,1))\n",
    "    for j in range(1,k):\n",
    "        c = c + abs(np.matmul(eigenVectors, np.reshape(R[:,j-1], (k,1))))    \n",
    "        i = np.unravel_index(c.argmin(), c.shape)\n",
    "        R[:,j] = np.transpose(eigenVectors[i[0]])\n",
    "    lastObjectiveValue = 0\n",
    "    for i in range(20):\n",
    "        eigenDiscrete = discetizationEigenVectorData(np.matmul(eigenVectors, R))\n",
    "        u,s,v = la.svd(np.matmul(np.transpose(eigenDiscrete), eigenVectors))\n",
    "        v=np.transpose(v)\n",
    "        NcutValue = 2*(n-np.sum(s))\n",
    "        if abs(NcutValue-lastObjectiveValue) < np.finfo(float).eps:\n",
    "            break\n",
    "        \n",
    "        lastObjectiveValue = NcutValue\n",
    "        R = np.matmul(v, np.transpose(u))\n",
    "    return eigenDiscrete\n",
    "    \n",
    "def SpectralClustering(affinity, K, type=3):\n",
    "    \n",
    "    d = np.sum(affinity, axis=1)\n",
    "    for it, i in enumerate(d):\n",
    "        if i == 0:\n",
    "            d[it] = np.finfo(float).eps\n",
    "            \n",
    "    D = np.diag(d)\n",
    "    L = D - affinity\n",
    "    if type == 1:\n",
    "        NL = L\n",
    "    elif type == 2:\n",
    "        Di = np.diag(1/d)\n",
    "        NL = Di * L\n",
    "    elif type == 3:\n",
    "        Di = np.diag(1/np.sqrt(d))\n",
    "        NL = np.matmul(Di,L)\n",
    "        NL = np.matmul(NL,Di)\n",
    "    \n",
    "    eig = la.eig(NL)\n",
    "    res = sorted(range(len(eig[0])), key=lambda k: eig[0][k])\n",
    "    U = eig[1][:,res[0:K]]\n",
    "    if type == 3:\n",
    "        U = normalize(U)\n",
    "    eigDiscrete = discretization(U)\n",
    "    labels = []\n",
    "    for row in eigDiscrete:\n",
    "        labels.append(np.unravel_index(row.argmax(), row.shape)[0])\n",
    "    for it, i in enumerate(labels):\n",
    "        labels[it] = i + 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b355631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snf\n",
    "from snf import get_n_clusters\n",
    "from data_convert import load_data_txt\n",
    "from random import seed\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "def generateCVRuns(data, N=10, K=5):\n",
    "    mats = []\n",
    "    seed(N)\n",
    "    for i in range(N):\n",
    "        seq = np.arange(len(data))\n",
    "        shuffle(seq)\n",
    "        mat = np.array_split(seq, K)\n",
    "        mats.append(mat)\n",
    "    return mats\n",
    "\n",
    "datas = load_data_txt(r\"C:\\Users\\tpavo\\Desktop\\Tirocinio\\tcga_aml\\OS\\0\\gene_tr_0_0.txt\", r\"C:\\Users\\tpavo\\Desktop\\Tirocinio\\tcga_aml\\OS\\0\\meth_tr_0_0.txt\", r\"C:\\Users\\tpavo\\Desktop\\Tirocinio\\tcga_aml\\OS\\0\\mirna_tr_0_0.txt\", r\"C:\\Users\\tpavo\\Desktop\\Tirocinio\\tcga_aml\\OS\\0\\labels_OS_tr_0_0.txt\")\n",
    "affinity_networks = snf.make_affinity(datas.data, K=20, mu=0.5)\n",
    "W = snf.snf(affinity_networks, K=20)\n",
    "lab = datas.labels\n",
    "clm = 'spectral'\n",
    "clustInfo = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8869a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snf_cv(W, lab, clm, infocl, K=5, N=10):\n",
    "    median_NMI = []\n",
    "    nsamp = len(W)\n",
    "    SNFNMI_all = []\n",
    "    cv_folds = generateCVRuns(lab)\n",
    "    for nfold in cv_folds:\n",
    "        SNFNMI_K = []\n",
    "        for row in nfold:\n",
    "            W_k = W[np.ix_(row, row)]\n",
    "            lab_k = []\n",
    "            for el in row:\n",
    "                lab_k.append(lab[el])\n",
    "            if clm == 'spectral':\n",
    "                if clustInfo:\n",
    "                    nclust = len(np.unique(lab))\n",
    "                    group_k = SpectralClustering(W_k, nclust)\n",
    "                else:\n",
    "                    nclust = get_n_clusters(W_k)\n",
    "                    group_k = SpectralClustering(W_k, nclust[0])\n",
    "            SNFNMI_K.append(normalized_mutual_info_score(group_k, lab_k))\n",
    "        median_NMI.append(np.median(SNFNMI_K))\n",
    "    median_NMI = np.median(median_NMI)\n",
    "    return median_NMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77b44be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08343009733226453"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snf_cv(W, lab, 'spectral', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c77a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snf\n",
    "from snf import get_n_clusters\n",
    "from data_convert import load_data_txt\n",
    "from random import seed\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "def generateCVRuns(data, N=10, K=5):\n",
    "    mats = []\n",
    "    seed(N)\n",
    "    for i in range(N):\n",
    "        seq = np.arange(len(data))\n",
    "        shuffle(seq)\n",
    "        mat = np.array_split(seq, K)\n",
    "        mats.append(mat)\n",
    "    return mats\n",
    "\n",
    "def snf_cv(W, lab, clm, infocl, K=5, N=10):\n",
    "    median_NMI = []\n",
    "    nsamp = len(W)\n",
    "    SNFNMI_all = []\n",
    "    cv_folds = generateCVRuns(lab)\n",
    "    for nfold in cv_folds:\n",
    "        SNFNMI_K = []\n",
    "        for row in nfold:\n",
    "            W_k = W[np.ix_(row, row)]\n",
    "            lab_k = []\n",
    "            for el in row:\n",
    "                lab_k.append(lab[el])\n",
    "            if clm == 'spectral':\n",
    "                if clustInfo:\n",
    "                    nclust = len(np.unique(lab))\n",
    "                    group_k = SpectralClustering(W_k, nclust)\n",
    "                else:\n",
    "                    nclust = get_n_clusters(W_k)\n",
    "                    group_k = SpectralClustering(W_k, nclust[0])\n",
    "            SNFNMI_K.append(normalized_mutual_info_score(group_k, lab_k))\n",
    "        median_NMI.append(np.median(SNFNMI_K))\n",
    "    median_NMI = np.median(median_NMI)\n",
    "    return median_NMI\n",
    "            \n",
    "\n",
    "def NMI_tuning(distL, K, alpha, lab, clm, infocl):\n",
    "    affinityL = snf.make_affinity(distL, K=K, mu=alpha)\n",
    "    W_K = snf.snf(affinityL, K=K)\n",
    "    return snf_cv(W_K, lab, clm=clm, infocl=infocl)\n",
    "\n",
    "def snf_tuning(distL, lab, clm, infocl):\n",
    "    #min and max K values\n",
    "    minK = 10\n",
    "    maxK = 30\n",
    "    stepK = 1\n",
    "    K_values = range(minK, maxK+stepK, stepK)\n",
    "    \n",
    "    #min and max alpha values\n",
    "    min_alpha = 0.3\n",
    "    max_alpha = 0.8\n",
    "    step_alpha = 0.05\n",
    "    alpha_values = np.arange(min_alpha, max_alpha+step_alpha, step_alpha)\n",
    "    \n",
    "    NMI_tun = Parallel(n_jobs=2)(delayed(NMI_tuning)(distL, k, alpha, lab, clm, infocl) for k in K_values for alpha in alpha_values)\n",
    "    \n",
    "    NMI_tun = np.array(NMI_tun)\n",
    "    NMI_tun = NMI_tun.reshape((len(K_values), len(alpha_values)))\n",
    "    \n",
    "    nk = len(K_values)\n",
    "    nalpha = len(alpha_values)\n",
    "    \n",
    "    idx_max_alpha_fk = []\n",
    "    max_nmi_fk = []\n",
    "    tab_median_NMI = []\n",
    "    \n",
    "    for elk in range(nk):\n",
    "        max_nmi_fk.append(np.max(NMI_tun[elk]))\n",
    "        tab_median_NMI.append(NMI_tun[elk])\n",
    "    \n",
    "    max_nmi_fk = np.array(max_nmi_fk)\n",
    "    \n",
    "    best_K_idx = np.unravel_index(max_nmi_fk.argmax(), max_nmi_fk.shape)\n",
    "    best_K = K_values[best_K_idx[0]]\n",
    "    \n",
    "    #for row in NMI_tun:\n",
    "    best_alpha_idx = np.unravel_index(NMI_tun[best_K_idx].argmax(), NMI_tun[best_K_idx].shape)\n",
    "    best_alpha = alpha_values[best_alpha_idx]\n",
    "\n",
    "    return Bunch(best_K=best_K, best_alpha=best_alpha, tab_median_NMI=tab_median_NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1e056c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_par = snf_tuning(affinity_networks, lab = lab, clm = 'spectral', infocl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0d3ea021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_K': 11, 'best_alpha': 0.5499999999999999, 'tab_median_NMI': [array([0.12131005, 0.11519019, 0.0826941 , 0.11140603, 0.11936152,\n",
      "       0.10806819, 0.11764578, 0.12199966, 0.11502914, 0.10867125,\n",
      "       0.1080683 ]), array([0.13429563, 0.10553455, 0.10242922, 0.09861518, 0.10960275,\n",
      "       0.13528792, 0.13262414, 0.10488109, 0.10488109, 0.09533931,\n",
      "       0.09154915]), array([0.12613001, 0.09704935, 0.07664708, 0.11882868, 0.1280269 ,\n",
      "       0.11820949, 0.10629535, 0.09673567, 0.0806998 , 0.0806998 ,\n",
      "       0.09533931]), array([0.11519019, 0.09959225, 0.10778404, 0.1048719 , 0.13189871,\n",
      "       0.10749772, 0.09416578, 0.08156439, 0.08296075, 0.08296075,\n",
      "       0.08386697]), array([0.10951784, 0.10347069, 0.10778404, 0.12839218, 0.13117329,\n",
      "       0.11878688, 0.07046227, 0.0806998 , 0.08296075, 0.07769534,\n",
      "       0.0806998 ]), array([0.10951784, 0.10242922, 0.1182314 , 0.13153856, 0.11363525,\n",
      "       0.10202644, 0.06023961, 0.07276485, 0.08828062, 0.04826252,\n",
      "       0.07400646]), array([0.0941867 , 0.09704935, 0.11150123, 0.13163465, 0.11319511,\n",
      "       0.07969165, 0.07668719, 0.09972832, 0.07701092, 0.06841798,\n",
      "       0.06931968]), array([0.08513316, 0.08972827, 0.11777857, 0.13126938, 0.10011555,\n",
      "       0.10370259, 0.07629898, 0.07855993, 0.07637993, 0.08866883,\n",
      "       0.07668719]), array([0.06703747, 0.09122969, 0.11863992, 0.11883657, 0.10011555,\n",
      "       0.08774668, 0.08527616, 0.06841798, 0.10100962, 0.08866883,\n",
      "       0.03575566]), array([0.08797104, 0.09897047, 0.1310278 , 0.10695439, 0.10299684,\n",
      "       0.08527616, 0.07400646, 0.06130974, 0.06130974, 0.05483384,\n",
      "       0.04719796]), array([0.10356326, 0.09122969, 0.1282076 , 0.10505126, 0.10450059,\n",
      "       0.06130974, 0.06153198, 0.06130974, 0.05270683, 0.04503572,\n",
      "       0.04503572]), array([0.09515907, 0.09122969, 0.1282076 , 0.10425325, 0.09725781,\n",
      "       0.08527616, 0.08189605, 0.07116438, 0.07116438, 0.05303605,\n",
      "       0.04904903]), array([0.09515907, 0.09122969, 0.11881931, 0.10425325, 0.06615762,\n",
      "       0.08527616, 0.08527616, 0.08527616, 0.09854148, 0.06454761,\n",
      "       0.06617205]), array([0.09515907, 0.09506893, 0.11836308, 0.08385822, 0.07263353,\n",
      "       0.05852175, 0.05918274, 0.08270564, 0.06454761, 0.06930368,\n",
      "       0.06007894]), array([0.09222953, 0.10496297, 0.09239425, 0.0654544 , 0.07263353,\n",
      "       0.05918274, 0.08270564, 0.07622973, 0.06615762, 0.06379481,\n",
      "       0.06322584]), array([0.09222953, 0.10496297, 0.08296075, 0.08527616, 0.07263353,\n",
      "       0.05918274, 0.07430092, 0.06782501, 0.05470195, 0.06021082,\n",
      "       0.05470195]), array([0.06831011, 0.09983684, 0.10299684, 0.07263353, 0.07263353,\n",
      "       0.07102352, 0.07102352, 0.06021082, 0.06196715, 0.05492419,\n",
      "       0.04719796]), array([0.09515907, 0.11733064, 0.10299684, 0.05011495, 0.07668719,\n",
      "       0.06782501, 0.07036253, 0.06454761, 0.06196715, 0.06183526,\n",
      "       0.05492419]), array([0.06593883, 0.11419624, 0.10299684, 0.06841798, 0.07668719,\n",
      "       0.07102352, 0.07036253, 0.06021082, 0.05645828, 0.05645828,\n",
      "       0.05668051]), array([0.06831011, 0.11419624, 0.07285842, 0.07668719, 0.07263353,\n",
      "       0.06704868, 0.07036253, 0.06183526, 0.06183526, 0.06915499,\n",
      "       0.06915499]), array([0.07471311, 0.11733064, 0.06087099, 0.07263353, 0.06446822,\n",
      "       0.07036253, 0.06617205, 0.05926097, 0.05492419, 0.06183526,\n",
      "       0.05702603])]}\n"
     ]
    }
   ],
   "source": [
    "print(opt_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "740ba651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist2(X):\n",
    "    X = np.array(X)\n",
    "    sumsqX = np.sum(X**2, axis=1)\n",
    "    XC = 2*(np.matmul(X, np.transpose(X)))\n",
    "    mat = []\n",
    "    for i in range(len(X)):\n",
    "        mat.append(sumsqX)\n",
    "    res = mat + np.transpose(mat) - XC\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X[0])):\n",
    "            if mat[i][j] < 0:\n",
    "                mat[i][j] = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "42029d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardNormalization(X):\n",
    "    X = np.array(X)\n",
    "    mean = np.mean(X, axis=0)\n",
    "    sd = np.std(X, axis=0, ddof = 1)\n",
    "    for it, i in enumerate(sd):\n",
    "        if sd[it] == 0:\n",
    "            sd[it] = 1\n",
    "    xNorm = (X - mean) / sd\n",
    "    return xNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8ecd0831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.35\n",
      "0.39999999999999997\n",
      "0.44999999999999996\n",
      "0.49999999999999994\n",
      "0.5499999999999999\n",
      "0.5999999999999999\n",
      "0.6499999999999999\n",
      "0.7\n",
      "0.7499999999999999\n",
      "0.7999999999999998\n"
     ]
    }
   ],
   "source": [
    "min_alpha = 0.3\n",
    "max_alpha = 0.8\n",
    "step_alpha = 0.05\n",
    "alpha_values = np.arange(min_alpha, max_alpha+step_alpha, step_alpha)\n",
    "for i in alpha_values:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "124f8b91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\tpavo\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\tpavo\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\tpavo\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\tpavo\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\tpavo\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\tpavo\\AppData\\Local\\Temp/ipykernel_7456/717662223.py\", line 2, in func\nNameError: name 'alpha' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7456/717662223.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mstep_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0malpha_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_alpha\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstep_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_alpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mNMI_tun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"spe\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK_values\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malpha_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mNMI_tun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "def func(k, alpham, ver):\n",
    "    return k+alpha\n",
    "minK = 10\n",
    "maxK = 30\n",
    "stepK = 1\n",
    "K_values = range(minK, maxK+stepK, stepK)\n",
    "ver = 'spe'\n",
    "    #min and max alpha values\n",
    "min_alpha = 0.3\n",
    "max_alpha = 0.8\n",
    "step_alpha = 0.05\n",
    "alpha_values = np.arange(min_alpha, max_alpha+step_alpha, step_alpha)\n",
    "NMI_tun = Parallel(n_jobs=2)(delayed(func)(k, alpha, \"spe\") for k in K_values for alpha in alpha_values)\n",
    "NMI_tun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c690b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import R_OK\n",
    "import snf\n",
    "from snf import get_n_clusters\n",
    "from snf.metrics import nmi\n",
    "from data_convert import load_data_txt\n",
    "from random import seed, randint\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.utils import Bunch\n",
    "from SpectralClustering import SpectralClustering\n",
    "from calNMI import calNMI\n",
    "\n",
    "def generateCVRuns(data, N=10, K=5):\n",
    "    mats = []\n",
    "    seed(N)\n",
    "    for i in range(N):\n",
    "        seq = []\n",
    "        for j in range(len(data)):\n",
    "            seq.append(randint(0,len(data)-1))\n",
    "        mat = np.array_split(seq, K)\n",
    "        mats.append(mat)\n",
    "    return mats\n",
    "\n",
    "def genMat(data, N=10, K=5):\n",
    "    mats=[]\n",
    "    for i in range(N):\n",
    "        seq=[j for j in range(63)]\n",
    "        mat = np.array_split(seq, K)\n",
    "        print(mat)\n",
    "        mats.append(mat)\n",
    "    return mats\n",
    "    \n",
    "def snf_cv(W, lab, clm, infocl, K=5, N=10):\n",
    "    median_NMI = []\n",
    "    cv_folds = genMat(lab)\n",
    "    for nfold in cv_folds:\n",
    "        SNFNMI_K = []\n",
    "        for row in nfold:\n",
    "            srow = np.sort(row)\n",
    "            W_k = W[np.ix_(srow, srow)]\n",
    "            lab_k = lab[np.ix_(srow)]\n",
    "            #if clm == 'spectral':\n",
    "            #    if infocl:\n",
    "            #        nclust = len(np.unique(lab))\n",
    "            #        group_k = SpectralClustering(W_k, nclust)\n",
    "            #    else:\n",
    "            nclust = get_n_clusters(W_k)\n",
    "            group_k = SpectralClustering(W_k, nclust[0])\n",
    "            SNFNMI_K.append(calNMI(group_k, lab_k))\n",
    "        median_NMI.append(np.median(SNFNMI_K))\n",
    "    median_NMI = np.median(median_NMI)\n",
    "    return median_NMI\n",
    "            \n",
    "\n",
    "def NMI_tuning(K, alpha, distL, lab, clm, infocl):\n",
    "    affinityL = snf.make_affinity(distL, K=K, mu=alpha)\n",
    "    W_K = snf.snf(affinityL, K=K)\n",
    "    #OK\n",
    "    return float(snf_cv(W_K, lab, clm=clm, infocl=infocl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ae33936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import axis\n",
    "from numpy import linalg as la\n",
    "import math\n",
    "\n",
    "def normalize(x):\n",
    "    res = []\n",
    "    for row in x:\n",
    "        res.append(np.divide(row,np.sqrt(np.sum(row**2))))\n",
    "    return res\n",
    "#OK\n",
    "def discretizationEigenVectorData(eigenVector):\n",
    "    Y = np.array([0.0 for _ in range(len(eigenVector[0])) for _ in range(len(eigenVector))])\n",
    "    Y = np.reshape(Y, (len(eigenVector), len(eigenVector[0])))\n",
    "    j = []\n",
    "    for row in eigenVector:\n",
    "        j.append(np.unravel_index(row.argmax(), row.shape)[0])\n",
    "    for it, i in enumerate(j):\n",
    "        Y[it][i] = 1\n",
    "    return Y \n",
    "#OK\n",
    "def discretization(eigenVectors):\n",
    "              \n",
    "    eigenVectors = normalize(np.array(eigenVectors, float))\n",
    "    n = len(eigenVectors)\n",
    "    k = len(eigenVectors[0])\n",
    "    R = np.array([0.0 for _ in range(k) for _ in range(k)])\n",
    "    R = np.reshape(R,  (k, k))\n",
    "    R[:,0] = np.transpose(eigenVectors[math.floor(n/2)])\n",
    "    c = np.array([0 for _ in range(n)])\n",
    "    c = np.reshape(c, (n,1))\n",
    "    for j in range(1,k):\n",
    "        c = c + abs(np.matmul(eigenVectors, np.reshape(R[:,j-1], (k,1))))    \n",
    "        i = np.unravel_index(c.argmin(), c.shape)\n",
    "        R[:,j] = np.transpose(eigenVectors[i[0]])\n",
    "    lastObjectiveValue = 0\n",
    "    for i in range(20):\n",
    "        eigenDiscrete = discretizationEigenVectorData(np.matmul(eigenVectors, R))\n",
    "        u,s,v = la.svd(np.matmul(np.transpose(eigenDiscrete), eigenVectors))\n",
    "        v = np.transpose(v)\n",
    "        NcutValue = 2*(n-np.sum(s))\n",
    "        if abs(NcutValue-lastObjectiveValue) < np.finfo(float).eps:\n",
    "            break\n",
    "        \n",
    "        lastObjectiveValue = NcutValue\n",
    "        R = np.matmul(v, np.transpose(u))\n",
    "    return eigenDiscrete\n",
    "    \n",
    "def SpectralClustering(affinity, K, type=3):\n",
    "    \n",
    "    d = np.sum(affinity, axis=1)\n",
    "    for it, i in enumerate(d):\n",
    "        if i == 0:\n",
    "            d[it] = np.finfo(float).eps\n",
    "            \n",
    "    D = np.diag(d)\n",
    "    L = D - affinity\n",
    "    if type == 1:\n",
    "        NL = L\n",
    "    elif type == 2:\n",
    "        Di = np.diag(1/d)\n",
    "        NL = Di * L\n",
    "    elif type == 3:\n",
    "        Di = np.diag(1/np.sqrt(d))\n",
    "        NL = np.matmul(Di,L)\n",
    "        NL = np.matmul(NL,Di)\n",
    "    \n",
    "    eigval, eigvec = la.eig(NL)\n",
    "    eigval = eigval.real\n",
    "    eigvec = eigvec.real\n",
    "    eigabs = abs(eigval)\n",
    "    res = sorted(range(len(eigabs)), key=lambda k: eigabs[k])\n",
    "    U = eigvec[:,res[0:K]]\n",
    "    if type == 3:\n",
    "        U = normalize(U)\n",
    "    U = np.array(U)\n",
    "    eigDiscrete = discretization(U)\n",
    "    labels = []\n",
    "    for row in eigDiscrete:\n",
    "        labels.append(np.unravel_index(row.argmax(), row.shape)[0])\n",
    "    for it, i in enumerate(labels):\n",
    "        labels[it] = i + 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39a05ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[-0.42008403 -0.81164467]\n",
      " [-0.47485808  0.57187832]\n",
      " [-0.52393683  0.11840916]\n",
      " [-0.56879646  0.01293785]]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "3\n",
      "[[-0.42008403 -0.81164467 -0.30685574]\n",
      " [-0.47485808  0.57187832 -0.59063084]\n",
      " [-0.52393683  0.11840916  0.74559427]\n",
      " [-0.56879646  0.01293785  0.03292341]]\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "[[0 2 1]\n",
      " [0 1 2]\n",
      " [1 2 0]\n",
      " [1 2 0]]\n",
      "4\n",
      "[[-0.42008403 -0.81164467 -0.30685574 -0.26571018]\n",
      " [-0.47485808  0.57187832 -0.59063084 -0.31403854]\n",
      " [-0.52393683  0.11840916  0.74559427 -0.39440924]\n",
      " [-0.56879646  0.01293785  0.03292341  0.82171726]]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[[0 2 3 1]\n",
      " [0 1 3 2]\n",
      " [1 2 3 0]\n",
      " [0 1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "from SpectralClustering import discretization\n",
    "\n",
    "W = [[1,5,9,13],[2,6,10,14],[3,7,11,15],[4,8,12,16]]\n",
    "NUMC = [2,3,4]\n",
    "W = (W+np.transpose(W))/2\n",
    "for i in range(len(W)):\n",
    "    W[i][i] = 0\n",
    "    \n",
    "if(len(NUMC)>0):\n",
    "    degs = np.sum(W, axis = 1)\n",
    "        \n",
    "    degs[degs==0] = np.finfo(float).eps\n",
    "    D = np.diag(degs)\n",
    "    L = D - W\n",
    "    Di = np.diag(1 / np.sqrt(degs))\n",
    "    L = np.matmul(np.matmul(Di, L), Di)\n",
    "        \n",
    "    eigs = la.eig(L)\n",
    "    eigsabs = abs(eigs[0])\n",
    "    eigs_order =  sorted(range(len(eigs[0])), key=lambda k: eigs[0][k])\n",
    "    eigsval = eigs[0][np.ix_(eigs_order)]\n",
    "    eigsvec = np.array(eigs[1][:,np.ix_(eigs_order)])\n",
    "    eigsvec = np.reshape(eigsvec, (len(eigsvec), len(eigsvec[0][0])))\n",
    "    eigengap = abs(np.diff(eigsval))\n",
    "    eigengap = eigengap * (1-eigsval[0:len(eigengap)])/(1-eigsval[1:len(eigsval)])\n",
    "        \n",
    "    quality = []\n",
    "    for ck in NUMC:\n",
    "        print(ck)\n",
    "        ind = np.array([i for i in range(ck)])\n",
    "        UU = eigsvec[:,np.ix_(ind)]\n",
    "        UU = np.reshape(UU, (len(UU), ck))\n",
    "        print(UU)\n",
    "        tmpidx = []\n",
    "        for it, row in enumerate(UU):\n",
    "            if np.sum(row)==0:\n",
    "                tmpidx.append(it)\n",
    "        for i in tmpidx:\n",
    "            UU[i] = np.finfo(float).eps\n",
    "        eigenVectorsDiscrete = discretization(UU)\n",
    "        eigenVectors = eigenVectorsDiscrete**2\n",
    "        print(eigenVectors)\n",
    "        order = np.argsort(eigenVectors)\n",
    "        print(order)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a7400119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3, 1],\n",
       "       [0, 1, 3, 2],\n",
       "       [1, 2, 3, 0],\n",
       "       [0, 1, 2, 3]], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96d223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
